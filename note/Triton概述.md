# Triton inferrence Server简介
一款开源推理服务软件，简化AI推理。  
***
同时支持在GPU、x86 和 ARM CPU 或 AWS Inferentia 上跨云、数据中心、边缘和嵌入式设备进行推理。  

能部署来自多个深度学习和机器学习框架的任何AI模型。{TensorRT、TensorFlow、PyTorch、ONNX、OpenVINO、Python、RAPIDS FIL}  

主要特点：
1. 

